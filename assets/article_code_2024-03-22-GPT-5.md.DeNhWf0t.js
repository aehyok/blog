import{_ as e,c as I,o as A,ag as n}from"./chunks/framework.Cpzi45lG.js";const P=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"article/code/2024-03-22-GPT-5.md","filePath":"article/code/2024-03-22-GPT-5.md","lastUpdated":1755852304000}'),a={name:"article/code/2024-03-22-GPT-5.md"};function r(G,p,O,t,o,i){return A(),I("div",null,p[0]||(p[0]=[n("<p>2024年3月19日,OpenAI CEO 奥特曼再度做客美国知名播客栏目Lex Friedman。</p><p>在这次持续了近两个小时的采访中，奥特曼深入剖析了董事会近期的变动，还畅谈了Ilya的未来动向、与马斯克起诉案相关的纷争，以及文字转视频工具Sora、豪掷7万亿美元的芯片计划、即将推出的新一代大语言模型GPT-5，乃至AGI的远景规划等。</p><hr><p>3月19日,OpenAI的CEO 奥特曼接受了Lex Fridman的采访,历时2个多小时。在这次采访中,奥特曼聊了很多大家可能感兴趣的话题,包括OpenAI的董事会之争、Ilya Sutskever的去留、Sora和Q* 的传说、以及GPT-5和AGI等等。</p><p>第一个话题是跟OpenAI董事会之争有关。奥特曼承认,从11月16日星期四开始的罢免风波,是他这一生中最痛苦的职业经历。混乱、羞耻、心烦,还有很多其他的负面情绪,整个人感觉非常糟。他也曾经设想过,通往AGI的道路肯定会充满激烈的权力角逐,这是一条必经之路。这件事过去的一个多月之后,他仿佛还处于一种恍惚状态,每天都感觉自己像漂流瓶一样,茫然四顿。他的精神完全崩溃了,情绪也陷入了极度低落。但是他还得坚持管理OpenAI,难度真的很大,只想找个洞穴钻进去,好好休养一阵子。不过,现在回过头来去看,这件事情还是有它的价值的。这可能不会是OpenAI最后一次面对如此大的压力,当时公司差点就垮了。所以在考虑AGI以外,如何打造一个有韧性的组织、如何构建一个能够承受世界压力的结构体系,也是非常关键的。</p><p>另外一个需要反思的是董事会。如果不特别制定规则的话,非营利组织的董事会,实际上掌握着很大的权力。他们并不真正向任何人负责,除了他们自己。虽然这样有它的好处,但是大家更希望的是OpenAI的董事会能够对全世界负责。新的董事会现在已经组建起来,虽然比较仓促,但是Brett和Larry是得到了现有团队和旧董事会的双重认可。他们有着更多的董事会工作经验,能够涵盖不同的专业领域。同时希望以整批的方式招募董事会成员,而不是一次聘用一个人。</p><p>董事会成员并不是每个人都要有很高的技术水平,但是有些人是必须的。虽然周六早上有两位董事会成员给奥特曼打电话,希望他回到OpenAI,但是周日晚上,董事会任命了一位新的临时CEO。那一刻让奥特曼感觉真的很难受。不过他最终高度评价了Mira Murati在事件中的表现,认为她是一个合格的领导者。他也希望公众对OpenAI的关注,不应该仅仅聚焦在那个戏剧化的周末,而是OpenAI整个发展的七年。</p><p>接下来,Fridman开始询问Ilya的近况。现在对Ilya的猜测都已经发展成网上的一个梗了,大家都以为被OpenAI关在哪了。奥特曼对此也很无奈,他对Ilya还是有着极大的敬意,希望能够持续合作。对于网上流传的Ilya看到AGI的段子,奥特曼很肯定的说,Ilya从来没有见过AGI,他们任何人都还没有。OpenAI也还没造出AGI。但是Ilya一直在思考AGI的安全问题,确保OpenAI在这个过程中能行得正、走得稳。他始终在以一种非常积极的方式进行灵魂的探索,并且总是持有一种长远的思考方式。他不太关心一年内会发生什么,而是在想象10年后的情况。</p><p>最近他俩还一起去了个晚宴,Ilya和一只小狗玩得也很开心,心情非常放松、让人感到亲切。不过随即两人又聊起了董事会的事。奥特曼说自己本来是个极度信任他人的人,他一向坚持的人生哲学是,不必太过担忧,不必在意那些偏执的疑虑和极端的可能性。但是被罢免的这件事,还是让他之后,在信任别人方面变得更加犹豫。不过他对于团队来说,仍然心中充满了巨大的感激、信任和尊重。他认为让自己被这样的人包围,是极其重要的。</p><p>接下来,Fridman和奥特曼又聊起了最近马斯克起诉OpenAI的事。奥特曼回顾了一下七八年前的情景,当时只是把OpenAI看做一个研究实验室,对技术的未来发展毫无头绪,甚至还没想到要开发一个API,或者卖聊天机器人的访问权限,也没有想过要产品化。后来他们意识到需要做出一些不同的事情,并且需要巨额的资本。所以他和马斯克就在想,行吧,当前的结构显然不太合适,那么应该怎样去补救。只不过补了一次又一次,最终双方都不太满意,然后马斯克决定离开。</p><p>马斯克觉得OpenAI快要失败了,想要完全的控制权来挽救局面。但是以奥特曼为主的一方,想要继续沿着现在OpenAI所走的方向前进。马斯克还想要特斯拉能够开展一个AGI项目,甚至在不同时间点有过多种想法,包括把OpenAI变成一个他能控制的盈利性公司,或者是让它与特斯拉合并。奥特曼等人并不同意这样做,于是马斯克就决定离开了。</p><p>对于起诉书中谈到的OpenAI中的Open代表什么,奥特曼认为如果可以重来,他可能会选一个不同的名字。OpenAI最重要的工作,是免费地将强大技术交到人们手中,作为一项公共福利。OpenAI没有在免费版本中投放广告,也没有通过其他途径来盈利。OpenAI的使命是免费为人们提供越来越强大的工具,并且让他们去使用。至于是否开源,他认为某些东西应该开源,而其他的则没必要。这种事往往会变成一种信仰之争,很难保持中立,只能去找到一个平衡点。</p><p>实际上在这里,奥特曼已经明确的表示了,OpenAI的Open不是指的开源,而是免费使用的意思,可能应该叫FreeAI更合适。在知道周末马斯克开源了Grok之后,奥特曼表示以后可能也会开源一些,可以在本地执行的小模型。</p><p>第四个话题是有关于Sora。奥特曼认为大模型对世界模型的理解,实际上比我们多数人给予的认可要深。虽然人们很容易一眼看出它们的不足,但是实际上并非全是假象,有些部分是有效的,有些部分则不然。从DALL·E 1到2再到3,再到Sora,每一版都会有人嘲讽,说它做不到这个,做不到那个,但是最终都被打脸。不过在Sora发布之前,还必须确保它的效率达到人们期望的规模,这样才能确保系统能够正常工作。还有大量的工作需要完成,比如像深度伪造、错误信息这样的问题。</p><p>对于Sora训练使用数据的版权问题,奥特曼肯定了,创造有价值数据的人们,应该得到某种形式的经济补偿,因为他们的数据被利用了。不过目前还不清楚具体的解决方案是什么,关键是得让创作者们拿到钱。</p><p>对于艺术家和创作者们的担心,奥特曼举了个例子,那就是艺术家们在摄影问世的时候也是忧心忡忡的。后来摄影却演变成了一种全新的艺术形式,有人通过摄影赚到了大钱。他相信类似的事情还会不断上演,人们会不断地用新工具探索新的创作方式。</p><p>奥特曼也重申AI的目的是处理更多的任务,而不是取代工作岗位,从而让人类能够在更高层次上进行抽象思考。以YouTube为例,以后可能很多视频在制作过程中,会运用到AI工具。但是视频的核心仍然是由人来思考、构思、负责部分执行,并且指导整个项目的运作。</p><p>接下来是大家之前比较关心的传闻Q*。奥特曼表示没传的那么邪乎,增强AI的推理能力是一个重要的发展方向,但是到目前为止还没能彻底攻克这个难题。大语言模型的性能,基本上是在沿着一个指数曲线逐步攀升。但是从旁观者,确实能感觉到有些跳跃性的进展。OpenAI采用的是迭代部署的方式,目前已经公开讨论了GPT-1、2、3和4,而不是直接秘密的开发GPT-5,就是因为AI不应该变成一种意外。OpenAI最明智的举措之一,就是让全世界都关注这一进程,正视AGI的重要性,考虑在我们陷入紧迫境地、不得不匆忙作出决策之前,需要建立什么样的系统、结构和治理模式。</p><p>OpenAI的目标绝不是给世界带来令人震惊的更新,而是恰恰相反。人们会对里程碑情有独钟,好像能够宣布某件事情取得了胜利,然后迈向下一个目标。但是这也可能会给大家带来一种错觉。所以奥特曼可能想换个形式来发布GPT-5。</p><p>Fridman接着开始询问GPT-5的事,甚至说道如果今年发布GPT-5的话,让奥特曼可以眨两下眼睛。奥特曼没接招,开始故弄玄虚,说今年会推出一个非常棒的新模型,但是还不确定会叫什么名字。而且在发布GPT-5之前,还有一系列重要的产品要发布。果然不愧是营销大师,吊足大家的胃口。</p><p>对于GPT-5,奥特曼用Ilya的一句话来评价,大概意思是,我们把200个中等规模的因素相互结合,创造出了一件巨大的作品。不过这里大飞我要再补充一下,在3月14日旧金山举行的OpenAI Match Day上,奥特曼还是透露了一些关于GPT-5的细节。总结下来就是一个字,强,两个字,碾压,四个字,超乎想象。</p><p>GPT-5将在高级推理功能上实现重大进步,性能改进将超出当前的预期,是类似GPT-3到GPT-4一样的质的跨越。顺便给了竞争对手一些打击,他警告说,许多创业公司认为GPT-5只是略有进步,将为他们提供更多的商业机会。但是这是一个错误的假设,如果按照这种思路,这些公司可能会被新一代的模型完全碾压,甚至摧毁。目前来看,今年应该肯定是会发布GPT-5的,只不过到时候是不是还叫GPT-5就不知道了,没准会换个名字。</p><p>接下来,奥特曼辟谣了7万亿美金的募资消息。他强调只是认为世界将需要巨量的计算能力,包括能源、数据中心、供应链以及芯片制造。有很多问题要去解决,人类对计算能力规模的渴求,可能会是难以想象的。奥特曼顺便又安利了一下自己投资的核聚变公司Helion,认为应该建造新的核反应堆。人类对核裂变已经深感恐惧,现在AGI也开始逐渐形成军备竞赛,需要把安全问题放到首位。</p><p>他认为可以将AGI开始的时间分为四个象限,慢起步的短时间线和长时间线,以及快起步的短时间线和长时间线。他觉得短时间线搭配慢起步是最安全的组合,也是最希望OpenAI能处于的状态。</p><p>随后两人谈到Google和Gemini。Fridman问奥特曼,谷歌过去20年已经成为了一个领头羊的角色,OpenAI现在会不会有意去取代。奥特曼回答,OpenAI并无意去复刻一个更卓越的谷歌搜索,而是希望找到一种全新的、更好的方法,来协助人们寻找、利用并整合信息。事实上,对于某些场景而言,ChatGPT已经做到了这一点,希望能应用到更多的场景中去。人们需要的是如何找到需要的答案或信息,世界也并不需要一个谷歌的翻版。 好的,以下是将字幕转换成文章的内容:</p><p>奥特曼还坦言自己对广告的商业模式不太认同。互联网早期发展的确需要依赖广告,但是那是暂时的。以后会有适合大语言模型的广告模式出现,也可以不带偏见地参与交易。广告领域会存在一场飞跃,不会干扰人们消费内容,不会干涉人们的消费行为,也不会为了迎合广告商而歪曲真相。</p><p>而对于最近Gemini 1.5版本爆出的黑人图像问题,Fridman也问道,如果企业内部有人类干预模型的安全性或者造成伤害,从而可能带来大量符合公司意识形态倾向的偏见,应该怎么办。</p><p>奥特曼用OpenAI团队中某个成员的点子来回答,那就是可以把模型应有的行为标准写出来并公开发布,接受大家的反馈,明确地表示这个模型应该是这样的表现,并且要阐释边缘情况。这样,当模型的行为不符合你的期望时,至少可以明确地知道这是公司需要解决的一个问题,还是它按照预期在运作,从而避免目前大模型偶尔会处于模棱两可的状态。</p><p>现在旧金山已经有点儿意识形态上的泡沫,科技界整体也是。许多公司都会受到意识形态的渗透,OpenAI也不例外。不过OpenAI因为对AGI的坚定信仰,相对排斥了一些其他的意识形态,暂时没有太大的问题出现。</p><p>随后两人又聊了聊对GPT-5和AGI的畅想。到GPT-5的时候,可能大家都不需要写代码了来编程了,也将会出现类人机器人,或者具有人类智能的机器人大脑。OpenAI也一定会重返AI机器人的行业,从最近我们做的关于FigureAI的节目中也可以印证这一点。</p><p>AGI并不是一个终点,它更像是一个开始,但是它其实更多是一个里程碑。奥特曼预计十年内AGI应该就会到来。他相信,只要一个系统能够显著加快全球科学发现的速度,那就是一件极其了不起的事情。他深信,大多数真正的经济增长都源自科学和技术的进步,不愧是有效加速主义的拥趸。</p><p>AGI有着巨大的力量,这种力量不应该被一个人所掌控,应有一个强健的治理体系才行。但这个问题啊,现在还难以解决。</p><p>后面剩下的时间呢,我觉得就是两个人纯粹在神侃了。说了半天,为什么奥特曼发推文只用小写,聊到对数学函数的着迷,Fridman还说自己准备去亚马逊雨林尝尝死藤水,甚至是聊到外星人,大家感兴趣的话可以自己去听一听。</p><p>最后呢,我想用奥特曼的一句话来结尾:AGI是否会更像是一个单独的大脑,还是会更像是联系我们每个人的社会基础设施,没人知道。但是重要的是,我们现在拥有的是我们所有人共同构建的知识和技能的框架。没有一个人能够独自发现所有的科学知识,但是我们可以利用这些知识,从而获得惊人的能力。所以从某种程度上来说,这是我们大家集体努力创造的成果,这让我对未来充满希望。</p>",34)]))}const l=e(a,[["render",r]]);export{P as __pageData,l as default};
