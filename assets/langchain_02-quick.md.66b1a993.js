import{_ as a,o as s,c as e,b as n}from"./app.54d7eac7.js";const g=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[{"level":2,"title":"快速入门指南","slug":"快速入门指南","link":"#快速入门指南","children":[]},{"level":2,"title":"安装","slug":"安装","link":"#安装","children":[]},{"level":2,"title":"环境设置","slug":"环境设置","link":"#环境设置","children":[]},{"level":2,"title":"构建语言模型应用程序：LLMs","slug":"构建语言模型应用程序-llms","link":"#构建语言模型应用程序-llms","children":[]},{"level":2,"title":"从语言模型中获取预测","slug":"从语言模型中获取预测","link":"#从语言模型中获取预测","children":[]},{"level":2,"title":"提示模板：管理 LLMs 的提示","slug":"提示模板-管理-llms-的提示","link":"#提示模板-管理-llms-的提示","children":[]}],"relativePath":"langchain/02-quick.md","lastUpdated":1708926478000}'),l={name:"langchain/02-quick.md"},p=n(`<h2 id="快速入门指南" tabindex="-1">快速入门指南 <a class="header-anchor" href="#快速入门指南" aria-hidden="true">#</a></h2><p>本教程让您快速了解如何使用 LangChain 构建端到端语言模型应用程序。</p><h2 id="安装" tabindex="-1">安装 <a class="header-anchor" href="#安装" aria-hidden="true">#</a></h2><p>首先，使用以下命令安装 LangChain：</p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#babed8;">pip install langchain</span></span>
<span class="line"><span style="color:#babed8;"># or</span></span>
<span class="line"><span style="color:#babed8;">conda install langchain -c conda-forge</span></span>
<span class="line"><span style="color:#babed8;"></span></span></code></pre></div><h2 id="环境设置" tabindex="-1">环境设置 <a class="header-anchor" href="#环境设置" aria-hidden="true">#</a></h2><p>使用 LangChain 通常需要与一个或多个模型提供者、数据存储、api 等集成。 对于这个例子，我们将使用 OpenAI 的 API，所以我们首先需要安装他们的 SDK：</p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#babed8;">pip install openai</span></span>
<span class="line"><span style="color:#babed8;"></span></span></code></pre></div><p>然后我们需要在终端中设置环境变量。</p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#babed8;">export OPENAI_API_KEY=&quot;...&quot;</span></span>
<span class="line"><span style="color:#babed8;"></span></span></code></pre></div><p>或者，您可以从 Jupyter notebook（或 Python 脚本）中执行此操作：</p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#babed8;">import os</span></span>
<span class="line"><span style="color:#babed8;">os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;...&quot;</span></span>
<span class="line"><span style="color:#babed8;"></span></span></code></pre></div><h2 id="构建语言模型应用程序-llms" tabindex="-1">构建语言模型应用程序：LLMs <a class="header-anchor" href="#构建语言模型应用程序-llms" aria-hidden="true">#</a></h2><p>现在我们已经安装了 LangChain 并设置了我们的环境，我们可以开始构建我们的语言模型应用程序了。 LangChain 提供了很多可以用来构建语言模型应用的模块。模块可以组合起来创建更复杂的应用程序，或者单独用于简单的应用程序。</p><h2 id="从语言模型中获取预测" tabindex="-1">从语言模型中获取预测 <a class="header-anchor" href="#从语言模型中获取预测" aria-hidden="true">#</a></h2><p>LangChain 最基本的构建块是在某些输入上调用 LLM。让我们通过一个简单的例子来说明如何做到这一点。为此，假设我们正在构建一项服务，该服务会根据公司的产品生成公司名称。 为此，我们首先需要导入 LLM 包装器。</p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#babed8;">from langchain.llms import OpenAI</span></span>
<span class="line"><span style="color:#babed8;"></span></span></code></pre></div><p>然后我们可以用任何参数初始化包装器。在此示例中，我们可能希望输出更加随机，因此我们将使用高温对其进行初始化。</p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#babed8;">llm = OpenAI(temperature=0.9)</span></span>
<span class="line"><span style="color:#babed8;"></span></span></code></pre></div><p>我们现在可以根据一些输入调用它！</p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#babed8;">text = &quot;What would be a good company name for a company that makes colorful socks?&quot;</span></span>
<span class="line"><span style="color:#babed8;">print(llm(text))</span></span>
<span class="line"><span style="color:#babed8;"></span></span></code></pre></div><p>有关如何在 LangChain 中使用 LLM 的更多详细信息，请参阅 LLM 入门指南。</p><h2 id="提示模板-管理-llms-的提示" tabindex="-1">提示模板：管理 LLMs 的提示 <a class="header-anchor" href="#提示模板-管理-llms-的提示" aria-hidden="true">#</a></h2><p>调用一个LLM大模型是重要的第一步，但这仅仅是个开始。通常，当您在应用程序中使用 LLM 时，您不会将用户输入直接发送到 LLM。相反，您可能正在接受用户输入并构建提示，然后将其发送给 LLM。</p>`,24),t=[p];function i(o,c,d,r,h,b){return s(),e("div",null,t)}const m=a(l,[["render",i]]);export{g as __pageData,m as default};
